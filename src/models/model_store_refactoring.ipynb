{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from typing import Tuple, List, Dict, Any, Optional\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# List of model types to evaluate\n",
    "MODELS = [\"linear\", \"randomforest\", \"xgboost\"]\n",
    "\n",
    "def get_model(model_name: str):\n",
    "    \"\"\"\n",
    "    Returns a model instance based on the model name.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_name : str\n",
    "        Name of the model to instantiate.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model\n",
    "        Instance of the requested model.\n",
    "    \"\"\"\n",
    "    if model_name == \"linear\":\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        return LinearRegression()\n",
    "    elif model_name == \"randomforest\":\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [None, 10, 20, 30],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        }\n",
    "\n",
    "        rf = RandomForestRegressor(random_state=42)\n",
    "        return GridSearchCV(rf, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "    elif model_name == \"xgboost\":\n",
    "        import xgboost as xgb\n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'learning_rate': [0.01, 0.1, 0.2]\n",
    "        }\n",
    "\n",
    "        xgb_model = xgb.XGBRegressor(random_state=42)\n",
    "        return GridSearchCV(xgb_model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model name: {model_name}\")\n",
    "\n",
    "def evaluate_model(model, model_name: str, X_test: pd.DataFrame, y_test: pd.Series) -> Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Evaluate a model using test data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : estimator\n",
    "        Trained model to evaluate.\n",
    "    model_name : str\n",
    "        Name of the model.\n",
    "    X_test : pd.DataFrame\n",
    "        Test features.\n",
    "    y_test : pd.Series\n",
    "        Test target values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (MAE, RMSE, R2) metrics.\n",
    "    \"\"\"\n",
    "    predictor = model if model_name == \"linear\" else model.best_estimator_\n",
    "\n",
    "    y_pred = predictor.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    return mae, rmse, r2\n",
    "\n",
    "def _data_hash(arrays) -> str:\n",
    "    \"\"\"\n",
    "    Generate a hash based on input data arrays.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arrays : list\n",
    "        List of arrays to hash.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Hexadecimal hash string.\n",
    "    \"\"\"\n",
    "    m = hashlib.sha256()\n",
    "    for arr in arrays:\n",
    "        m.update(\n",
    "            arr.to_numpy().tobytes()\n",
    "            if isinstance(arr, (pd.Series, pd.DataFrame))\n",
    "            else arr.tobytes()\n",
    "        )\n",
    "    return m.hexdigest()[:12]\n",
    "\n",
    "def _model_path(model_name: str, data_hash: str, option_type: Optional[str] = None) -> Path:\n",
    "    \"\"\"\n",
    "    Generate a path for saving a model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_name : str\n",
    "        Name of the model.\n",
    "    data_hash : str\n",
    "        Hash of the training data.\n",
    "    option_type : str, optional\n",
    "        Type of option ('call' or 'put').\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Path\n",
    "        Path where the model should be saved.\n",
    "    \"\"\"\n",
    "    models_dir = Path(\"models\")\n",
    "    models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    if option_type:\n",
    "        return models_dir / f\"{model_name}_{option_type}_{data_hash}_{timestamp}.joblib\"\n",
    "    else:\n",
    "        return models_dir / f\"{model_name}_{data_hash}_{timestamp}.joblib\"\n",
    "\n",
    "def _save_model(model: Any, path: Path) -> None:\n",
    "    \"\"\"\n",
    "    Save a model to disk.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : Any\n",
    "        Model to save.\n",
    "    path : Path\n",
    "        Path where to save the model.\n",
    "    \"\"\"\n",
    "    path.parent.mkdir(exist_ok=True, parents=True)\n",
    "    joblib.dump(model, path, compress=(\"xz\", 3))\n",
    "    print(f\"Saved model to {path}\")\n",
    "\n",
    "def _load_model(path: Path) -> Any:\n",
    "    \"\"\"\n",
    "    Load a model from disk.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : Path\n",
    "        Path to the model file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Any\n",
    "        Loaded model.\n",
    "    \"\"\"\n",
    "    if path.exists():\n",
    "        print(f\"Loading model from {path}\")\n",
    "        return joblib.load(path)\n",
    "    return None\n",
    "\n",
    "def get_latest_model(model_name: str, option_type: Optional[str] = None) -> Tuple[Any, Optional[Path]]:\n",
    "    \"\"\"\n",
    "    Get the latest model of the specified type.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_name : str\n",
    "        Name of the model to retrieve.\n",
    "    option_type : str, optional\n",
    "        Type of option ('call' or 'put').\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (model, path) or (None, None) if no model is found.\n",
    "    \"\"\"\n",
    "    models_dir = Path(\"models\")\n",
    "    if not models_dir.exists():\n",
    "        return None, None\n",
    "\n",
    "    pattern = f\"{model_name}_\"\n",
    "    if option_type:\n",
    "        pattern += f\"{option_type}_\"\n",
    "    pattern += \"*.joblib\"\n",
    "\n",
    "    model_files = list(models_dir.glob(pattern))\n",
    "\n",
    "    if not model_files:\n",
    "        return None, None\n",
    "\n",
    "    # Sort by modification time (most recent first)\n",
    "    model_files.sort(key=os.path.getmtime, reverse=True)\n",
    "    latest_model_path = model_files[0]\n",
    "\n",
    "    # Load the latest model\n",
    "    model = _load_model(latest_model_path)\n",
    "\n",
    "    return model, latest_model_path\n",
    "\n",
    "def fit_model(model_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
